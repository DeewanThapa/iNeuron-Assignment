{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2435498b-e26a-4170-ab72-604e856469c1",
   "metadata": {},
   "source": [
    "1.\tDefine the Bayesian interpretation of probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521e7be9-32a6-415c-abc5-e52f5ba52fc4",
   "metadata": {},
   "source": [
    "A1. The Bayesian interpretation of probability views probability as a degree of belief or confidence in a proposition, rather than as a frequency of occurrence. It is based on the idea that probability is subjective and can change as new information is acquired.\n",
    "\n",
    "In this interpretation, probability is represented as a conditional probability, where the belief in a proposition is conditioned on the available evidence. Bayes' theorem is a fundamental equation in Bayesian probability that allows us to update our beliefs based on new evidence.\n",
    "\n",
    "Key points of the Bayesian interpretation:\n",
    "\n",
    "Subjectivity: Probabilities are not objective frequencies but rather subjective degrees of belief.\n",
    "Conditional probability: Probabilities are always conditional on the available information.\n",
    "Bayes' theorem: This theorem provides a way to update probabilities based on new evidence.\n",
    "Prior and posterior probabilities: The prior probability is the initial belief in a proposition, while the posterior probability is the updated belief after considering new evidence.\n",
    "In contrast to the frequentist interpretation of probability, which defines probability as the relative frequency of an event in a large number of trials, the Bayesian interpretation focuses on the degree of belief in a proposition based on available information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5e37f1-a7ae-405f-a0b1-b8e255a41052",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60aa3abe-c8f0-44b9-9d5a-d7850395be09",
   "metadata": {},
   "source": [
    "2.\tDefine probability of a union of two events with equation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f65fcb7-e1c4-45a8-b00a-8dec8915ef1e",
   "metadata": {},
   "source": [
    "A2. Probability of the Union of Two Events\n",
    "\n",
    "The probability of the union of two events, A and B, is the probability that either event A occurs, event B occurs, or both occur. It is denoted as P(A ∪ B).\n",
    "\n",
    "Equation:\n",
    "\n",
    "P(A ∪ B) = P(A) + P(B) - P(A ∩ B)\n",
    "where:\n",
    "\n",
    "P(A ∪ B) is the probability of A or B occurring.\n",
    "P(A) is the probability of event A occurring.\n",
    "P(B) is the probability of event B occurring.\n",
    "P(A ∩ B) is the probability of both A and B occurring (the intersection of A and B).   \n",
    "Explanation:\n",
    "\n",
    "The formula adds the probabilities of A and B to account for the cases where either event occurs. However, this double-counts the cases where both events occur. Therefore, we subtract the probability of the intersection to avoid overcounting.\n",
    "\n",
    "Example:\n",
    "\n",
    "If the probability of rain tomorrow is 0.4 (P(Rain)), the probability of wind tomorrow is 0.3 (P(Wind)), and the probability of both rain and wind is 0.2 (P(Rain ∩ Wind)), then the probability of either rain or wind or both is:\n",
    "\n",
    "P(Rain ∪ Wind) = 0.4 + 0.3 - 0.2 = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51105fc-6179-4fbc-b69f-8eb8c2f6c351",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b5902f7-86fc-41b1-ba0c-529f9393b38a",
   "metadata": {},
   "source": [
    "3.\tWhat is joint probability? What is its formula?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889b210b-9d05-4116-a70f-4d9a2f397368",
   "metadata": {},
   "source": [
    "A3. Joint Probability\n",
    "\n",
    "Joint probability is the probability of two or more events occurring simultaneously. It is often denoted as P(A ∩ B) for events A and B.\n",
    "\n",
    "Formula:\n",
    "\n",
    "P(A ∩ B) = P(A|B) * P(B) = P(B|A) * P(A)\n",
    "where:\n",
    "\n",
    "P(A ∩ B) is the joint probability of A and B.\n",
    "P(A|B) is the conditional probability of A given that B has occurred.\n",
    "P(B|A) is the conditional probability of B given that A has occurred.\n",
    "P(A) is the marginal probability of A.\n",
    "P(B) is the marginal probability of B.\n",
    "Explanation:\n",
    "\n",
    "The formula states that the joint probability of A and B can be calculated in two ways:\n",
    "\n",
    "Conditional probability of A given B: Multiply the probability of B occurring by the conditional probability of A given that B has occurred.\n",
    "Conditional probability of B given A: Multiply the probability of A occurring by the conditional probability of B given that A has occurred.\n",
    "Both methods yield the same result.\n",
    "\n",
    "Example:\n",
    "\n",
    "If the probability of rain tomorrow is 0.4 (P(Rain)) and the probability of wind tomorrow given that it rains is 0.6 (P(Wind|Rain)), then the joint probability of both rain and wind tomorrow is:\n",
    "\n",
    "P(Rain ∩ Wind) = P(Wind|Rain) * P(Rain) = 0.6 * 0.4 = 0.24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a767a038-4007-41fa-9ed0-838ddce69f77",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12c28f64-a81f-4dde-a1b7-b2e933fb4ae1",
   "metadata": {},
   "source": [
    "4.\tWhat is chain rule of probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eb92d0-420b-443f-9af6-3b6284d96a9f",
   "metadata": {},
   "source": [
    "A4. Chain Rule of Probability\n",
    "\n",
    "The chain rule of probability is a fundamental rule that allows us to calculate the joint probability of a sequence of events. It states that the joint probability of a sequence of events A1, A2, ..., An is equal to the product of the conditional probabilities of each event given the occurrence of its predecessors.\n",
    "\n",
    "Formula:\n",
    "\n",
    "P(A1 ∩ A2 ∩ ... ∩ An) = P(An|A1, A2, ..., An-1) * P(An-1|A1, A2, ..., An-2) * ... * P(A2|A1) * P(A1)\n",
    "where:\n",
    "\n",
    "P(A1 ∩ A2 ∩ ... ∩ An) is the joint probability of A1, A2, ..., An.\n",
    "P(Ai|A1, A2, ..., Ai-1) is the conditional probability of Ai given the occurrence of A1, A2, ..., Ai-1.\n",
    "Explanation:\n",
    "\n",
    "The chain rule essentially breaks down the joint probability into a series of conditional probabilities, making it easier to calculate. It is a powerful tool in probability theory and has applications in various fields, including statistics, machine learning, and physics.\n",
    "\n",
    "Example:\n",
    "\n",
    "Suppose we have three events: A, B, and C. The joint probability of A, B, and C occurring can be calculated using the chain rule as follows:\n",
    "\n",
    "P(A ∩ B ∩ C) = P(C|A, B) * P(B|A) * P(A)\n",
    "This means that the probability of all three events occurring is equal to the probability of C given that A and B have occurred, multiplied by the probability of B given that A has occurred, multiplied by the probability of A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f729b922-bc7a-4a7f-a836-dcb724cff3c2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3aa52ab5-e92c-4f98-9fc4-ac46e9e6837a",
   "metadata": {},
   "source": [
    "5.\tWhat is conditional probability means? What is the formula of it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80656785-8581-40bb-9613-357ddfeb9f48",
   "metadata": {},
   "source": [
    "A5. Conditional Probability\n",
    "\n",
    "Conditional probability is the probability of one event (A) occurring given that another event (B) has already occurred. It is denoted as P(A|B).\n",
    "\n",
    "Formula:\n",
    "\n",
    "P(A|B) = P(A ∩ B) / P(B)\n",
    "where:\n",
    "\n",
    "P(A|B) is the conditional probability of A given B.\n",
    "P(A ∩ B) is the joint probability of A and B.\n",
    "P(B) is the marginal probability of B.\n",
    "Explanation:\n",
    "\n",
    "The formula states that the conditional probability of A given B is equal to the joint probability of A and B divided by the probability of B. This means that we are considering only the cases where B has occurred and calculating the probability of A within that subset of cases.   \n",
    "\n",
    "Example:\n",
    "\n",
    "If the probability of rain tomorrow is 0.4 (P(Rain)) and the probability of both rain and wind tomorrow is 0.2 (P(Rain ∩ Wind)), then the conditional probability of rain given that there is wind is:\n",
    "\n",
    "P(Rain|Wind) = P(Rain ∩ Wind) / P(Wind) = 0.2 / 0.3 = 2/3\n",
    "\n",
    "This means that if we know that there is wind tomorrow, the probability of rain is 2/3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3e506d-e283-4013-bb0a-fb88e22a3840",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "082d9f08-65d8-4b43-8dcd-29fbdb74ce1c",
   "metadata": {},
   "source": [
    "6.\tWhat are continuous random variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d7ec30-4afa-4dc0-b02e-31784ff6215c",
   "metadata": {},
   "source": [
    "A6. Continuous Random Variables\n",
    "\n",
    "Continuous random variables are variables that can take on any value within a specified range or interval. Unlike discrete random variables, which have a countable number of possible values, continuous random variables can have an infinite number of possible values.   \n",
    "\n",
    "Examples of continuous random variables:\n",
    "\n",
    "Height: The height of a person can take on any value within a certain range (e.g., 1.5 meters to 2.0 meters).\n",
    "Weight: The weight of an object can take on any value within a certain range (e.g., 50 kg to 100 kg).\n",
    "Time: The time it takes to complete a task can take on any value within a certain range (e.g., 0 to 60 minutes).\n",
    "Temperature: The temperature of a room can take on any value within a certain range (e.g., 15 degrees Celsius to 30 degrees Celsius).\n",
    "Probability density function (PDF):\n",
    "\n",
    "The probability distribution of a continuous random variable is described by a probability density function (PDF). The PDF gives the probability of the variable falling within a certain range of values. Note that the probability of a continuous random variable taking on a specific value is zero.   \n",
    "\n",
    "Cumulative distribution function (CDF):\n",
    "\n",
    "The cumulative distribution function (CDF) of a continuous random variable gives the probability that the variable is less than or equal to a certain value. It is the integral of the PDF.\n",
    "\n",
    "Key points to remember:\n",
    "\n",
    "Continuous random variables can take on any value within a specified range.\n",
    "The probability of a continuous random variable taking on a specific value is zero.\n",
    "The probability distribution of a continuous random variable is described by a probability density function (PDF).\n",
    "The cumulative distribution function (CDF) gives the probability that the variable is less than or equal to a certain value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f9e0ba-4a0c-43e7-9930-d80019190d54",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a6dbe2e-b40b-42d2-a970-11c063af12e1",
   "metadata": {},
   "source": [
    "7.\tWhat are Bernoulli distributions? What is the formula of it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff11994c-985c-43c6-b7ed-2e3dbb4d816c",
   "metadata": {},
   "source": [
    "A7. Bernoulli Distributions\n",
    "\n",
    "A Bernoulli distribution is a discrete probability distribution that describes the outcome of a single binary experiment (an experiment with only two possible outcomes). The two outcomes are typically labeled as \"success\" and \"failure.\"\n",
    "\n",
    "Examples of Bernoulli experiments:\n",
    "\n",
    "Flipping a coin (heads or tails)\n",
    "Rolling a die and checking if it lands on 6 (success or failure)\n",
    "Checking if a customer makes a purchase (yes or no)\n",
    "Parameters:\n",
    "\n",
    "The Bernoulli distribution has one parameter, denoted as p, which represents the probability of success.\n",
    "\n",
    "Probability Mass Function (PMF):\n",
    "\n",
    "The probability mass function (PMF) of a Bernoulli random variable X is given by:\n",
    "\n",
    "P(X = x) = p^x * (1-p)^(1-x)\n",
    "where:\n",
    "\n",
    "x can take on the values 0 or 1 (0 for failure, 1 for success)\n",
    "p is the probability of success\n",
    "Mean and Variance:\n",
    "\n",
    "Mean: E(X) = p\n",
    "Variance: Var(X) = p * (1-p)\n",
    "Key points to remember:\n",
    "\n",
    "A Bernoulli distribution models a single binary experiment.\n",
    "The parameter p represents the probability of success.\n",
    "The PMF gives the probability of the variable taking on the values 0 or 1.\n",
    "The mean and variance of a Bernoulli distribution are simple functions of the parameter p."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f415179b-21d7-43f6-9abc-e868f5ed8c83",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f733861f-f889-4421-8723-7a38ca7e1611",
   "metadata": {},
   "source": [
    "8.\tWhat is binomial distribution? What is the formula?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400e12e9-c851-40e7-a6db-a93cab50c66b",
   "metadata": {},
   "source": [
    "A8. Binomial Distribution\n",
    "\n",
    "A binomial distribution is a discrete probability distribution that describes the number of successes in a fixed number of independent Bernoulli trials. Each trial has the same probability of success, p.\n",
    "\n",
    "Examples of binomial experiments:\n",
    "\n",
    "Flipping a coin 10 times and counting the number of heads\n",
    "Rolling a die 20 times and counting the number of times it lands on 6\n",
    "Surveying 100 people and counting the number of people who prefer a certain product\n",
    "Parameters:\n",
    "\n",
    "The binomial distribution has two parameters:\n",
    "\n",
    "n: The number of Bernoulli trials\n",
    "p: The probability of success in each trial\n",
    "Probability Mass Function (PMF):\n",
    "\n",
    "The probability mass function (PMF) of a binomial random variable X is given by:\n",
    "\n",
    "P(X = k) = C(n, k) * p^k * (1-p)^(n-k)\n",
    "where:\n",
    "\n",
    "k is the number of successes (0 ≤ k ≤ n)\n",
    "C(n, k) is the binomial coefficient, which represents the number of ways to choose k successes from n trials. It is calculated as:\n",
    "C(n, k) = n! / (k! * (n-k)!)\n",
    "p is the probability of success in each trial\n",
    "(1-p) is the probability of failure in each trial\n",
    "Mean and Variance:\n",
    "\n",
    "Mean: E(X) = n * p\n",
    "Variance: Var(X) = n * p * (1-p)\n",
    "Key points to remember:\n",
    "\n",
    "A binomial distribution models the number of successes in a fixed number of independent Bernoulli trials.\n",
    "The parameters n and p determine the shape of the distribution.\n",
    "The PMF gives the probability of a specific number of successes.\n",
    "The mean and variance of a binomial distribution are simple functions of n and p."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7049c331-9968-4e9c-8f1b-54c8f2681b5a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08868570-8cc6-4840-91c1-5a3c0d65d7a2",
   "metadata": {},
   "source": [
    "9.\tWhat is Poisson distribution? What is the formula?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e6849d-0fb9-49fd-9228-6c175d200768",
   "metadata": {},
   "source": [
    "A9. Poisson Distribution\n",
    "\n",
    "A Poisson distribution is a discrete probability distribution that describes the number of occurrences of an event in a fixed interval of time or space. It is often used to model rare events that occur independently of each other.\n",
    "\n",
    "Examples of Poisson events:\n",
    "\n",
    "The number of phone calls received by a call center in an hour\n",
    "The number of car accidents on a highway per day\n",
    "The number of bacteria in a sample of water\n",
    "Parameter:\n",
    "\n",
    "The Poisson distribution has one parameter, denoted as λ (lambda), which represents the average rate of occurrences of the event per unit of time or space.\n",
    "\n",
    "Probability Mass Function (PMF):\n",
    "\n",
    "The probability mass function (PMF) of a Poisson random variable X is given by:\n",
    "\n",
    "P(X = k) = (λ^k * e^(-λ)) / k!\n",
    "where:\n",
    "\n",
    "k is the number of occurrences (0 ≤ k ≤ ∞)\n",
    "λ is the average rate of occurrences\n",
    "e is the mathematical constant approximately equal to 2.71828\n",
    "k! is the factorial of k\n",
    "Mean and Variance:\n",
    "\n",
    "Mean: E(X) = λ\n",
    "Variance: Var(X) = λ\n",
    "Key points to remember:\n",
    "\n",
    "A Poisson distribution models the number of occurrences of an event in a fixed interval.\n",
    "The parameter λ represents the average rate of occurrences.\n",
    "The PMF gives the probability of a specific number of occurrences.\n",
    "The mean and variance of a Poisson distribution are equal to the parameter λ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09feb6b2-161f-474f-930d-2aa0170057b8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a81609e-01fc-4c5b-ba4e-df79795747d7",
   "metadata": {},
   "source": [
    "10.\tDefine covariance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea0135d-a5ef-4c22-9aeb-b799febba060",
   "metadata": {},
   "source": [
    "A10. Covariance is a statistical measure that quantifies the relationship between two variables. It indicates how much two variables vary together. If two variables tend to increase or decrease together, they have a positive covariance. If one variable increases while the other decreases, they have a negative covariance.   \n",
    "\n",
    "Formula:\n",
    "\n",
    "Cov(X, Y) = E[(X - μX)(Y - μY)]\n",
    "where:\n",
    "\n",
    "Cov(X, Y) is the covariance between variables X and Y.\n",
    "E is the expected value operator.\n",
    "μX is the mean of variable X.\n",
    "μY is the mean of variable Y.\n",
    "Interpretation:\n",
    "\n",
    "Positive covariance: When X increases, Y tends to increase as well.\n",
    "Negative covariance: When X increases, Y tends to decrease.\n",
    "Zero covariance: There is no linear relationship between X and Y.\n",
    "It's important to note that covariance is sensitive to the scale of the variables. To measure the strength of the relationship between variables independent of their scale, correlation is often used. Correlation is calculated by dividing the covariance by the product of the standard deviations of the two variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ace8dfe-db80-41d5-bfae-d7e2703b2130",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f371a40-8bc5-4569-9d76-a1112b8636c8",
   "metadata": {},
   "source": [
    "11.\tDefine correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3bc16c-38a7-4540-acb5-804d60ef5d15",
   "metadata": {},
   "source": [
    "A11. Correlation is a statistical measure that quantifies the strength and direction of the linear relationship between two variables. It ranges from -1 to 1.   \n",
    "\n",
    "-1: Perfect negative correlation: The variables move in opposite directions (e.g., as one variable increases, the other decreases).   \n",
    "0: No correlation: There is no linear relationship between the variables.\n",
    "1: Perfect positive correlation: The variables move in the same direction (e.g., as one variable increases, the other increases).\n",
    "Formula:\n",
    "\n",
    "Correlation(X, Y) = Cov(X, Y) / (σX * σY)\n",
    "where:\n",
    "\n",
    "Correlation(X, Y) is the correlation between variables X and Y.\n",
    "Cov(X, Y) is the covariance between variables X and Y.\n",
    "σX is the standard deviation of variable X.\n",
    "σY is the standard deviation of variable Y.\n",
    "Interpretation:\n",
    "\n",
    "A correlation coefficient close to 1 or -1 indicates a strong linear relationship between the variables.\n",
    "A correlation coefficient close to 0 indicates a weak or no linear relationship between the variables.\n",
    "The sign of the correlation coefficient indicates the direction of the relationship (positive or negative).   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7738984-c232-4afe-967a-df6eba37f1bc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "192802d1-5df2-45ff-92ee-948076b23d65",
   "metadata": {},
   "source": [
    "12.\tDefine sampling with replacement. Give example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4438543d-b93a-4ce5-bea2-6affad1fb95f",
   "metadata": {},
   "source": [
    "A12. Sampling with Replacement\n",
    "\n",
    "Sampling with replacement is a sampling technique where each selected item is put back into the population before the next item is selected. This means that the same item can be selected multiple times in a single sample.\n",
    "\n",
    "Example:\n",
    "\n",
    "Imagine you have a bag containing 5 marbles: 3 red and 2 blue. If you sample with replacement, you could draw a red marble, put it back in the bag, and then draw another red marble. This is because the red marble is replaced after each draw, so it can be drawn again.\n",
    "\n",
    "Contrast with Sampling Without Replacement:\n",
    "\n",
    "In sampling without replacement, once an item is selected, it is not put back into the population. This means that an item can only be selected once in a single sample.\n",
    "\n",
    "Applications of Sampling with Replacement:\n",
    "\n",
    "Bootstrapping: A statistical technique used to estimate the sampling distribution of a statistic.\n",
    "Monte Carlo simulations: A method for simulating the behavior of a system or process.\n",
    "Polling and surveys: Sampling with replacement can be used to collect data from a large population.\n",
    "Advantages of Sampling with Replacement:\n",
    "\n",
    "Simpler analysis: Statistical calculations can be simpler when sampling with replacement.\n",
    "Can be used with smaller populations: Even with small populations, sampling with replacement can provide accurate estimates.\n",
    "Disadvantages of Sampling with Replacement:\n",
    "\n",
    "Increased variance: Sampling with replacement can lead to a slightly higher variance in the sample statistics compared to sampling without replacement.\n",
    "May not be appropriate for certain situations: In some cases, sampling without replacement is more appropriate, such as when the population is small and the goal is to estimate the proportion of items with a certain characteristic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b483fdda-6170-481d-a966-4efbc001a474",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d51d1604-461b-4a48-bfc9-80303c919b59",
   "metadata": {},
   "source": [
    "13.\tWhat is sampling without replacement? Give example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c1ff01-3480-4601-95ec-573456f2c3c8",
   "metadata": {},
   "source": [
    "A13. Sampling Without Replacement\n",
    "\n",
    "Sampling without replacement is a sampling technique where each selected item is not put back into the population before the next item is selected. This means that an item can only be selected once in a single sample.\n",
    "\n",
    "Example:\n",
    "\n",
    "Imagine you have a bag containing 5 marbles: 3 red and 2 blue. If you sample without replacement, you could draw a red marble, keep it out of the bag, and then draw another marble. Since the red marble is not replaced, it cannot be drawn again.\n",
    "\n",
    "Contrast with Sampling With Replacement:\n",
    "\n",
    "In sampling with replacement, each selected item is put back into the population before the next item is selected, allowing for the same item to be selected multiple times.\n",
    "\n",
    "Applications of Sampling Without Replacement:\n",
    "\n",
    "Quality control: Inspecting a sample of items from a production line to check for defects.\n",
    "Market research: Surveying a sample of consumers to gather their opinions.\n",
    "Scientific experiments: Collecting samples from a population to study a particular phenomenon.\n",
    "Advantages of Sampling Without Replacement:\n",
    "\n",
    "Reduced variance: Sampling without replacement can lead to a lower variance in the sample statistics compared to sampling with replacement.\n",
    "More accurate estimates: For smaller populations, sampling without replacement can provide more accurate estimates of population parameters.\n",
    "Disadvantages of Sampling Without Replacement:\n",
    "\n",
    "More complex analysis: Statistical calculations can be more complex when sampling without replacement.\n",
    "May not be possible for large populations: For very large populations, it may be impractical or impossible to sample without replacement.\n",
    "In summary:\n",
    "\n",
    "Sampling with replacement allows for the same item to be selected multiple times.\n",
    "Sampling without replacement ensures that each item is selected only once.\n",
    "The choice between sampling with or without replacement depends on the specific situation and the desired level of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b942aa-d312-4cec-986d-f4a64bbe0da3",
   "metadata": {},
   "source": [
    "14.\tWhat is hypothesis? Give example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4121803a-334e-4920-ab6c-cc831a689c05",
   "metadata": {},
   "source": [
    "A14. Hypothesis\n",
    "\n",
    "A hypothesis is a proposed explanation for a phenomenon or a statement that can be tested through experimentation or observation. It is a tentative answer to a research question.\n",
    "\n",
    "Example:\n",
    "\n",
    "Research question: Does studying for longer hours improve exam scores?\n",
    "Hypothesis: Students who study for more hours will achieve higher exam scores than students who study for fewer hours.\n",
    "In this example, the hypothesis is a testable statement that can be evaluated through research. It suggests a relationship between studying hours and exam scores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
